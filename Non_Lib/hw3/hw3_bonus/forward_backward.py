#import statements
import numpy as np
import torch

blank_id = 0

def extend(tgt_seq):
	"""
	This function takes target sequence as the input and returns the extended sequence 
	obtained after appending blanks
	input:
		- tgt_seq: A list containg target sequence vocabulary numbers, 
				   for instance, if we have the below vocabulary:
				   vocab = {
				   "-":0,
				   "a":1,
				   "b":2,
				   "c":3
				   }
				   and the target sequence is "abbc", tgt_seq will be [1,2,2,3]	
	 
	 output:
		- Sext: extended sequence obtained after appending blanks, for the above example it would be
				[0, 1, 0, 2, 0, 2, 0, 3, 0]
	"""
	#you can assume blank index to be 0 always

	return NotImplemented
	

def forward(prob_vecs, Sext):
	"""
	Implement the CTC forward function here.
	This function takes the probability vector (output y) generated by the model and Sext (Extended target sequence) as 
	inputs and returns the forward probabilities vector alpha.
	input:
		- prob_vecs: A 2D-Numpy array of the shape [input_length,vocabulary size] that contains the output symbol probabilities 
					 produced by the model
		- Sext: The extended sequence after appending blanks, as returned by the extend function
	 
	output:
		- alpha: Forward probabilities vector of the shape [input_length, len(Sext)]
	"""
	"""
	YOUR CODE HERE
	"""
	
	return NotImplemented


def backward(prob_vecs, Sext):
	"""
	Implement the CTC backward function here.
	This function takes the probability vector (output y) generated by the model and Sext (Extended target sequence) as 
	inputs and returns the backward probabilities vector beta.
	input:
		- prob_vecs: A 2D-Numpy Array of the shape [input_length,vocabulary size] that contains the output symbol probabilities 
					 produced by the model
		-Sext: The extended sequence after appending blanks, as returned by the extend function
	 
	output:
		- beta: backward probabilities vector of the shape [input_length, len(Sext)]
	"""
	"""
	YOUR CODE HERE
	"""
	return NotImplemented


def compute_posterior(prob_vecs, tgt_seq):
	"""
	Compute the posteriors given alpha and beta.
	This function takes the probability vector (output y) generated by the model and Sext (Extended target sequence) as 
	inputs and returns the posterior vector gamma.
	input:
		- prob_vecs: A 2D-Numpy Array of the shape [input_length,vocabulary size] that contains the output symbol probabilities 
					 produced by the model
		-tgt_seq: The target sequence as defined in the extend function
	 
	output:
		- gamma: posterior vector of the shape [input_length, len(Sext)]
	"""
	Sext  = extend(tgt_seq) # extend target sequence 
	alpha = forward(prob_vecs, Sext) # forward probabilities computed
	beta  = backward(prob_vecs, Sext) # backward probabilities computed
	input_len, _ = prob_vecs.shape #gamma dimension 0
	seq_len = len(Sext) #gamma dimension 1
	gamma = np.zeros((input_len, seq_len), dtype=np.float) # we have initialised gamma for you here,
														   # you must compute gamma values using alpha and beta
	"""
	YOUR CODE HERE
	"""
			
	return NotImplemented


def compute_derivative(prob_vecs, tgt_seq):
	"""
	Compute the final derivatives dy.
	This function takes the probability vector (output y) generated by the model and target sequence (tgt_seq) as 
	inputs and returns the derivatives.
	input:
		- prob_vecs: A 2D-Numpy Array of the shape [input_length,vocabulary size] that contains the output symbol probabilities 
					 produced by the model
		-tgt_seq: The target sequence as defined in the extend function
	 
	output:
		- dy: derivatives wrt each symbol, shape: [input_length,vocabulary size]
	"""
	#extend the target sequence
	Sext = extend(tgt_seq)
	#obtain gamma, the posterior vector
	gamma = compute_posterior(prob_vecs, tgt_seq)
	#initialise dy
	dy = np.zeros((prob_vecs.shape[0], prob_vecs.shape[1]), dtype=np.float)
	#compute dy from gamma and prob_vecs(output y)
	"""
	YOUR CODE HERE
	"""
	return NotImplemented
			





